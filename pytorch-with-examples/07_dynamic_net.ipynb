{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_dynamic_net.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMaM46lGOTGh1CHhmBot5V/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/desaiankitb/pytorch-basics/blob/main/pytorch-with-examples/07_dynamic_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3BKQSw37NQH"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSS9Yh5HEmKi"
      },
      "source": [
        "#PyTorch: Control Flow + Weight Sharing\n",
        "To showcase the power of PyTorch dynamic graphs, we will implement a very strange model: a third-fifth order polynomial that on each forward pass chooses a random number between 3 and 5 and uses that many orders, resuing the same weights multiple times to compute the forth and fifth order. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5erwtnyElaN",
        "outputId": "23349ce1-ca10-4f98-9e5e-84f78d0a1f69"
      },
      "source": [
        "import random \n",
        "import torch \n",
        "import math \n",
        "\n",
        "class DynamicNet(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    \"\"\"\n",
        "    In the constructor we instantiate five parameters and assign them as members. \n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.a = torch.nn.Parameter(torch.randn(()))\n",
        "    self.b = torch.nn.Parameter(torch.randn(()))\n",
        "    self.c = torch.nn.Parameter(torch.randn(()))\n",
        "    self.d = torch.nn.Parameter(torch.randn(()))\n",
        "    self.e = torch.nn.Parameter(torch.randn(()))\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    For the forward pass of the model, we randomly choose either 4 or 5\n",
        "    and reuse the e parameter to compute the contribution of these orders. \n",
        "\n",
        "    Since each forward pass builds a dynamic computation graph, we can use normal\n",
        "    Python control-flow operators like loops or conditional statements when \n",
        "    defining the forward pass of the model. \n",
        "\n",
        "    Here we also see that it is perfectly safe to reuse the same parameter many\n",
        "    times when defining a computational graph. \n",
        "    \"\"\"\n",
        "    y = self.a + self.b * x + self.c * x ** 2 + self.d * x ** 3\n",
        "    for exp in range(4, random.randint(4,6)):\n",
        "      y = y + self.e * x ** exp \n",
        "    return y \n",
        "\n",
        "  def string(self):\n",
        "    \"\"\"\n",
        "    Just like any class in Python, you can also define custom method on \n",
        "    PyTorch modules \n",
        "    \"\"\"\n",
        "    x = f'y = ' \n",
        "    y = f'{\" %.4f + \"}'%self.a.item() \n",
        "    z = f'{\" %.4f x + \"}'%self.b.item()  \n",
        "    w = f'{\" %.4f x^2 + \"}'%self.c.item()  \n",
        "    a = f'{\" %.4f x^3 +\"}'%self.d.item()\n",
        "    b = f'{\" %.4f x^4 ?\"}'%self.e.item()\n",
        "    c = f'{\" %.4f x^5 ?\"}'%self.e.item()\n",
        "    return x+y+z+w+a+b+c\n",
        "\n",
        "# Create Tensors to hold input and outputs. \n",
        "x = torch.linspace(-math.pi, math.pi, 2000)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# Construct our model by instantiating the class defined above \n",
        "model = DynamicNet()\n",
        "\n",
        "# Construct our loss function and an Optimizer. Training this strange model with\n",
        "# vanilla stochastic gradient descent is tough, so we use momentum \n",
        "criterion = torch.nn.MSELoss(reduction='sum')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-8, momentum=0.9)\n",
        "for t in range(3000):\n",
        "   # Forward pass: Compute predicted y by passing x to the model \n",
        "   y_pred = model(x)\n",
        "   # Compute and print loss \n",
        "   loss = criterion(y_pred, y)\n",
        "   if t % 100 == 99:\n",
        "     print(t, loss.item())\n",
        "\n",
        "   # Zero gradients, perform a backward pass, and update the weights. \n",
        "   optimizer.zero_grad()\n",
        "   loss.backward()\n",
        "   optimizer.step()\n",
        "\n",
        "\n",
        "print(f'Result: {model.string()}')\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 21088106.0\n",
            "199 243403.953125\n",
            "299 1509.9053955078125\n",
            "399 2187.60009765625\n",
            "499 2908.666748046875\n",
            "599 1204.462646484375\n",
            "699 1166.0146484375\n",
            "799 1121.0164794921875\n",
            "899 1078.45166015625\n",
            "999 1027.33837890625\n",
            "1099 991.9153442382812\n",
            "1199 961.5921020507812\n",
            "1299 939.3413696289062\n",
            "1399 898.3304443359375\n",
            "1499 854.445068359375\n",
            "1599 822.7882690429688\n",
            "1699 821.8604125976562\n",
            "1799 760.6082763671875\n",
            "1899 802.4473876953125\n",
            "1999 711.8200073242188\n",
            "2099 661.5264892578125\n",
            "2199 650.8818359375\n",
            "2299 638.4863891601562\n",
            "2399 597.8087768554688\n",
            "2499 575.25439453125\n",
            "2599 558.0422973632812\n",
            "2699 561.4852294921875\n",
            "2799 510.6127014160156\n",
            "2899 515.29443359375\n",
            "2999 478.595458984375\n",
            "Result: y =  0.4050 +  0.3032 x +  -0.0676 x^2 +  -0.0131 x^3 + -0.0005 x^4 ? -0.0005 x^5 ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op_CfrA0ISXg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}