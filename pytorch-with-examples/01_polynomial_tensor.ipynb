{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_polynomial_tensor.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM82Ztu4Bj8QHcAsN7s802E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/desaiankitb/pytorch-basics/blob/main/pytorch-with-examples/01_polynomial_tensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdXkO8QJ0ZmB"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxl_IwSX0iGx"
      },
      "source": [
        "#PyTorch: Tensors \n",
        "A third order polynomial, trained to predict $y = sin(x)$ from $-\\pi$ to $\\pi$ by minimizing squared Euclidean distance. \n",
        "\n",
        "This implementation uses PyTorch tensors to manually compute the forward pass, loss and backward pass. \n",
        "\n",
        "A PyTorch Tensor is basically the same as a numpy array: it does not know anything about deep learning or computational graphs or gradients, and is just a generic n-dimensional array to be used for arbitary numeric computation. \n",
        "\n",
        "The biggest difference between a numpy array and a PyTorch Tensor is that a PyTorch Tensor can run on either CPU or GPU. To run operations on the GPU, just cast the Tensor to a cuda datatype. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy_lOSQt1YZS",
        "outputId": "f55d7f46-24ce-4f2d-f1bb-1eb8b1ea439e"
      },
      "source": [
        "import torch\n",
        "import math \n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "# device = torch.device((\"cuda:0\") # Uncomment this to run on GPU\n",
        "                      \n",
        "# Create random input and output data \n",
        "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# Randomly initialize weights \n",
        "a = torch.randn((), device=device, dtype=dtype)\n",
        "b = torch.randn((), device=device, dtype=dtype)\n",
        "c = torch.randn((), device=device, dtype=dtype)\n",
        "d = torch.randn((), device=device, dtype=dtype)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(2000):\n",
        "  # Forward pass: compute predicted y\n",
        "  y_pred = a + b * x + c * x ** 2 + d * x ** 3 \n",
        "\n",
        "  # Compute and print loss \n",
        "  loss = (y_pred - y).pow(2).sum().item()\n",
        "  if t % 100 == 99: \n",
        "    print(t, loss)\n",
        "\n",
        "  # Backprop to compute gradients of a, b, c, d with respect to loss \n",
        "  grad_y_pred = 2.0 * (y_pred - y)\n",
        "  grad_a = grad_y_pred.sum()\n",
        "  grad_b = (grad_y_pred * x).sum()\n",
        "  grad_c = (grad_y_pred * x ** 2).sum()\n",
        "  grad_d = (grad_y_pred * x ** 3).sum()\n",
        "\n",
        "  # Update weights using gradient descent \n",
        "  a -= learning_rate * grad_a\n",
        "  b -= learning_rate * grad_b \n",
        "  c -= learning_rate * grad_c\n",
        "  d -= learning_rate * grad_d\n",
        "\n",
        "\n",
        "print(f\"Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 4057.933837890625\n",
            "199 2704.05810546875\n",
            "299 1803.617431640625\n",
            "399 1204.5255126953125\n",
            "499 805.7750854492188\n",
            "599 540.2608642578125\n",
            "699 363.3869323730469\n",
            "799 245.50755310058594\n",
            "899 166.9075927734375\n",
            "999 114.47176361083984\n",
            "1099 79.47185516357422\n",
            "1199 56.09714889526367\n",
            "1299 40.47702407836914\n",
            "1399 30.032434463500977\n",
            "1499 23.044004440307617\n",
            "1599 18.364957809448242\n",
            "1699 15.229874610900879\n",
            "1799 13.127795219421387\n",
            "1899 11.717279434204102\n",
            "1999 10.770027160644531\n",
            "Result: y = -0.024517834186553955 + 0.8201571702957153 x + 0.004229733254760504 x^2 + -0.08812667429447174 x^3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA-5AKd23XeJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}